# Critical Reproduction: Distribution-Aware Reweighting (HAM10000)
# æ‰¹åˆ¤æ€§å¤ç°ï¼šåŸºäºåˆ†å¸ƒæ„ŸçŸ¥çš„çš®è‚¤ç—…å˜åˆ†ç±»é‡åŠ æƒ

> **"Theory is continuous, but data is discrete - and often biased."**
> **â€œç†è®ºæ˜¯è¿ç»­çš„ï¼Œä½†æ•°æ®æ˜¯ç¦»æ•£çš„â€”â€”ä¸”å¾€å¾€å……æ»¡åè§ã€‚â€**

---

## 1. Project Overview (é¡¹ç›®æ¦‚è¿°)

### ğŸ‡¨ğŸ‡³ ä¸­æ–‡è¯´æ˜
æœ¬é¡¹ç›®å¤ç°äº†è®ºæ–‡ "Mitigating Individual Skin Tone Bias in Skin Lesion Classification through Distribution-Aware Reweighting" çš„æ ¸å¿ƒæ–¹æ³•ã€‚

æœ¬é¡¹ç›®æ—¨åœ¨éªŒè¯ä¸€ä¸ªå…³é”®å‡è®¾ï¼š**åœ¨æåº¦ä¸å¹³è¡¡çš„å°æ ·æœ¬åŒ»ç–—æ•°æ®é›†ä¸Šï¼Œæ•°å­¦ä¸Šçš„åˆ†å¸ƒå¯¹é½æ˜¯å¦çœŸèƒ½å¸¦æ¥å…¬å¹³æ€§æ”¶ç›Šï¼Ÿ**

åŸè®ºæ–‡æå‡ºä»ç¦»æ•£ç±»åˆ«ï¼ˆFitzpatrick I-VIï¼‰è½¬å‘åŸºäº ITA (Individual Typology Angle) çš„è¿ç»­åˆ†å¸ƒè¯„ä¼°ã€‚é€šè¿‡ **æ ¸å¯†åº¦ä¼°è®¡ (KDE)** å¯¹è‚¤è‰²åˆ†å¸ƒå»ºæ¨¡ï¼Œå¹¶æ ¹æ®æ ·æœ¬åœ¨åˆ†å¸ƒç©ºé—´ä¸­çš„â€œè·ç¦»â€è¿›è¡Œåå‘åŠ æƒã€‚

**å·²å®ç°çš„åŠ æƒåº¦é‡ (Implemented Metrics):**
* **FS (Fidelity Similarity / Bhattacharyya):** è¡¡é‡åˆ†å¸ƒé‡å åº¦ã€‚
* **WD (Wasserstein Distance 1-D):** è¡¡é‡åˆ†å¸ƒå˜æ¢æ‰€éœ€çš„â€œæ¨åœŸæœºè·ç¦»â€ã€‚
* **PF (Patrick-Fisher Distance):** åˆ†å¸ƒé—´çš„æ¬§æ°è·ç¦»ã€‚
* **BS (Baseline):** åŸºå‡†çº¿ï¼Œæ— åŠ æƒ (æƒé‡æ’ä¸º 1.0) ä»¥ä¾›å¯¹æ¯”ã€‚

### ğŸ‡ºğŸ‡¸ English Description
This repository reproduces the methodology from "Mitigating Individual Skin Tone Bias in Skin Lesion Classification through Distribution-Aware Reweighting".

The project serves as a critical examination of the hypothesis: **Can mathematical distribution alignment genuinely mitigate bias in severely imbalanced, small-scale medical datasets?**

Moving beyond discrete subgroups (Fitzpatrick Skin Types), this method utilizes **Kernel Density Estimation (KDE)** on the continuous Individual Typology Angle (ITA) to reweight the loss function based on distribution distance.

---

## 2. Dataset Preparation (æ•°æ®å‡†å¤‡)

**âš ï¸ CRITICAL:** The code's `_resolve_paths` logic expects a strict directory structure relative to the source code. You must combine data from two sources into the `data/` directory.ï¼ˆyou can also change the input_dir my parameterï¼‰

**âš ï¸ æ³¨æ„ï¼š** ä»£ç ä¸­çš„è·¯å¾„è§£æé€»è¾‘ä¾èµ–äºç›¸å¯¹è·¯å¾„ã€‚è¯·åŠ¡å¿…å°†ä¸¤ä¸ªæ¥æºçš„æ•°æ®åˆå¹¶è‡³ `data/` ç›®å½•ä¸­ã€‚(å¯é€šè¿‡å‚æ•°è°ƒæ•´è¾“å…¥åœ°å€ï¼‰

### Data Sources (æ•°æ®æº)
1.  **Images & Masks (å›¾åƒä¸åˆ†å‰²æ©ç ):**
    * Source: [HAM1000 Segmentation and Classification (Kaggle)](https://www.kaggle.com/datasets/surajghuwalewala/ham1000-segmentation-and-classification)
    * *Action:* Extract images to `data/images` and masks to `data/masks`.
2.  **Original Metadata (åŸå§‹å…ƒæ•°æ®) CVS only ---- å¯ä»¥åªæŠŠmetadata.cvsä¸‹è½½ä¸‹æ¥ï¼ˆcan download metadata.cvs onlyï¼‰:**
    * Source: [Skin Cancer MNIST: HAM10000 (Kaggle)](https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000)
    * *Action:* Place `HAM10000_metadata.csv` in `data/`. This is required for lesion-level split to prevent data leakage.

### Directory Structure (ç›®å½•ç»“æ„)

```text
.
â”œâ”€â”€ code/                 # Source code (overall_q.py, etc.)
â”œâ”€â”€ data/                 # DATASET ROOT
â”‚   â”œâ”€â”€ images/           # [Required] All .jpg images
â”‚   â”œâ”€â”€ masks/            # [Required] Segmentation masks (*_segmentation.png)
â”‚   â”œâ”€â”€ HAM10000_metadata.csv  # [Required] Original metadata for lesion_id
â”‚   â”œâ”€â”€ GroundTruth.csv   # [Input] Your main label file
â”‚   â””â”€â”€ results/          # [Output] Training results
â””â”€â”€ requirements.txt

```

---

## 3. Usage (ä½¿ç”¨è¯´æ˜)

### Installation (å®‰è£…)

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

```

### 1. Preprocessing (æ•°æ®é¢„å¤„ç†)

Before training, you must generate the ITA (skin tone) quality features.
è®­ç»ƒå‰å¿…é¡»ç”Ÿæˆ ITA è‚¤è‰²è´¨é‡ç‰¹å¾ã€‚

```bash
# This will generate 'ita_medians.csv' in your output directory
python code/overall_q.py \
  --csv-path data/GroundTruth.csv \
  --output-dir data/qi

```

### 2. Training (æ¨¡å‹è®­ç»ƒ)

Run the main training pipeline. You can customize the **input CSV** and **output directory**.
è¿è¡Œä¸»è®­ç»ƒæµç¨‹ã€‚ä½ å¯ä»¥è‡ªå®šä¹‰**è¾“å…¥ CSV** å’Œ **è¾“å‡ºç›®å½•**ã€‚

**Example (FS Mode):**

```bash
python code/overall_q.py \
  --csv-path data/GroundTruth.csv \
  --output-dir data/qi \
  --mode fs \
  --epochs 10 \
  --batch-size 256 \
  --num-folds 7 \
  --learning-rate 1e-5 \
  --seed 42

```

### 3. Testing Only (ä»…æµ‹è¯•)

If you have trained models and want to evaluate them on a test set:
å¦‚æœå·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶å¸Œæœ›è¿›è¡Œæµ‹è¯•è¯„ä¼°ï¼š

```bash
python code/overall_q.py \
  --csv-path data/GroundTruth.csv \
  --output-dir data/qi \
  --mode fs \
  --run-test-only

```

### 4. Comparison (ç»“æœå¯¹æ¯”)

Generate comparison plots for all modes (BS/FS/WD/PF).
ç”Ÿæˆæ‰€æœ‰æ¨¡å¼çš„å¯¹æ¯”å›¾è¡¨ã€‚

```bash
python code/compare_skin_tone.py

```

---

## 4. Arguments (å‚æ•°è¯´æ˜)

| Argument | Default | Description |
| --- | --- | --- |
| `--csv-path` | `None` | **[Custom Input]** Path to the input CSV file (containing 'image', 'diagnosis'). |
| `--output-dir` | `None` | **[Custom Output]** Directory to save results, checkpoints, and logs. |
| `--mode` | `fs` | Reweighting mode: `bs` (Baseline), `fs`, `wd`, `pf`. |
| `--epochs` | `10` | Number of training epochs per fold. |
| `--batch-size` | `256` | Batch size for dataloaders. |
| `--num-folds` | `7` | Number of folds for Cross-Validation. |
| `--run-test-only` | `False` | Skip training and run evaluation on existing checkpoints. |
| `--seed` | `42` | Random seed for reproducibility. |

---

## 5. Critical Analysis (æ‰¹åˆ¤æ€§åˆ†æ)

### ğŸ‡¨ğŸ‡³ å®éªŒç»“è®ºï¼šå±€é™æ€§ä¸­çš„å…¬å¹³æ€§æ›™å…‰

æœ¬é¡¹ç›®çš„å®éªŒæ­ç¤ºäº†åœ¨æç«¯ä¸å¹³è¡¡æ•°æ®ä¸‹ï¼Œç®—æ³•ä¿®æ­£ä¸æ•°æ®è´¨é‡ä¹‹é—´çš„åšå¼ˆã€‚

1. **é•¿å°¾åˆ†å¸ƒçš„æŒ‘æˆ˜ä¸é€‚åº” (The Challenge of Long-Tail):**
   HAM10000 æ•°æ®é›†ä¸­ï¼Œæ·±è‰²çš®è‚¤ï¼ˆType 5 & 6ï¼‰æ ·æœ¬æåº¦ç¨€ç¼ºï¼ˆæµ‹è¯•é›†å¸¸ä¸è¶³ 10 ä¾‹ï¼‰ã€‚è™½ç„¶è¿™å¯¼è‡´æ ¸å¯†åº¦ä¼°è®¡ (KDE) çš„ç¨³å®šæ€§å—åˆ°æŒ‘æˆ˜ï¼Œä½†å®éªŒè¡¨æ˜ï¼Œåˆ†å¸ƒåŠ æƒç®—æ³•ï¼ˆFS/WDï¼‰å¹¶æœªå®Œå…¨å¤±æ•ˆã€‚ç›¸åï¼Œå®ƒåœ¨æœ‰é™çš„æ ·æœ¬ç©ºé—´å†…ä¾ç„¶å°è¯•æ•æ‰åˆ†å¸ƒå·®å¼‚ï¼Œå¹¶ç»™å‡ºäº†æ•°å­¦ä¸Šåˆç†çš„æƒé‡ä¿®æ­£ã€‚

2. **å¾®å¼±ä½†ç§¯æçš„å…¬å¹³æ€§ä¿¡å· (Subtle yet Positive Fairness Signals):**
   å°½ç®¡å°æ ·æœ¬å¯¼è‡´æŒ‡æ ‡æ³¢åŠ¨è¾ƒå¤§ï¼Œä½†å¯¹æ¯”æ•°æ®å¯è§ï¼Œ**å¼•å…¥åˆ†å¸ƒåŠ æƒï¼ˆFS/WD/PFï¼‰åï¼Œç¨€ç¼ºæ ·æœ¬ï¼ˆType 5 & 6ï¼‰çš„ F1-Macro æŒ‡æ ‡æ™®éä¼˜äºæ— åŠ æƒçš„åŸºå‡†çº¿ï¼ˆBSï¼‰ã€‚** è¿™è¯æ˜äº†ç®—æ³•åœ¨â€œå…³æ³¨å°‘æ•°æ´¾â€è¿™ä¸€æ ¸å¿ƒç›®æ ‡ä¸Šæ˜¯ç”Ÿæ•ˆçš„â€”â€”å³ä¾¿åœ¨æ•°æ®æåº¦åŒ®ä¹çš„æƒ…å†µä¸‹ï¼Œåå‘åŠ æƒæœºåˆ¶ä¾ç„¶å¸®åŠ©æ¨¡å‹æ›´å‡†ç¡®åœ°è¯†åˆ«äº†è¾¹ç¼˜ç¾¤ä½“ã€‚

3. **ç»“è®º (Conclusion):**
   ç®—æ³•å¹¶éä¸‡èƒ½è¯ï¼Œä½†å®ƒæ˜¯ä¸€é“æœ‰æ•ˆçš„é˜²çº¿ã€‚å®éªŒè¯æ˜ï¼Œ**æ•°æ®ä»£è¡¨æ€§è™½æ˜¯æ ¹æœ¬ï¼Œä½†åœ¨æ•°æ®å­˜åœ¨ç»“æ„æ€§ç¼ºå¤±æ—¶ï¼Œåˆ†å¸ƒæ„ŸçŸ¥é‡åŠ æƒï¼ˆDRWï¼‰ä»èƒ½æä¾›æ¯”é»˜è®¤è®­ç»ƒæ›´ä¼˜çš„å…¬å¹³æ€§ä¿éšœ**ï¼Œå°½ç®¡è¿™ç§æå‡åœ¨æå°æ ·æœ¬ä¸‹æ˜¾å¾—è¾ƒä¸ºå¾®å¼±ã€‚

### ğŸ‡ºğŸ‡¸ Empirical Analysis: Fairness Amidst Scarcity

This reproduction highlights the nuanced interaction between algorithmic correction and data quality in extremely imbalanced settings.

1. **Constraints of the Long-Tail:**
   The extreme scarcity of dark skin tones (Type 5 & 6) in HAM10000 poses a significant challenge to Kernel Density Estimation (KDE). However, the distribution-aware algorithms (FS/WD) did not completely fail. Instead, they functioned within the limits of the data, attempting to model the distribution shift and apply logical reweighting even with minimal support.

2. **Marginal but Consistent Fairness Gains:**
   While small sample sizes introduce statistical noise, a direct comparison reveals a crucial trend: **Distribution-aware methods (FS/WD/PF) consistently achieved higher F1-Macro scores on the rare Type 5 & 6 categories compared to the unweighted Baseline (BS).** This validates the algorithm's core premise: the inverse reweighting mechanism successfully forced the model to prioritize underrepresented samples, mitigating bias to the extent allowed by the data.

3. **Conclusion:**
   Algorithms cannot fully compensate for structural data deficits, but they serve as a necessary safeguard. The results demonstrate that while **data representation is primary, Distribution-Aware Reweighting (DRW) offers a tangible, albeit subtle, improvement in fairness over standard training**, acting as a critical correction mechanism when diverse data is unavailable.

```

```
